# -*- coding: utf-8 -*-
"""Q4.ipynb

Automatically generated by Colaboratory.

"""

from google.colab import drive
drive.mount('/content/drive')

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.optim.lr_scheduler import _LRScheduler
import torch.utils.data as data

import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.utils.data import Dataset, DataLoader
from sklearn import decomposition
from sklearn import manifold
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import random
import seaborn as sns
from PIL import Image
import sklearn.metrics as metrics

import torchvision.models as models
alexnet=models.alexnet(pretrained=True)

SEED = 1234
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)
torch.backends.cudnn.deterministic = True

class CustomData(Dataset): 
    def __init__(self, data, label, transform=None):
        self.data = data
        self.label = label
        self.transform = transform
        self.img_shape = data.shape
        
    def __getitem__(self, index):
        img = Image.fromarray(self.data[index])
        label = self.label[index]
        if self.transform is not None:
            img = self.transform(img)
        else:
            img_to_tensor = transforms.ToTensor()
            img = img_to_tensor(img)
        return img, label
        
    def __len__(self):
        return len(self.data)
class NeuralNet(nn.Module):
    def __init__(self, input_dim, output_dim):
        super().__init__()   
        self.input_fc = nn.Linear(input_dim, 512)
        self.hidden_fc = nn.Linear(512,256)
        self.output_fc = nn.Linear(256, output_dim)
        
    def forward(self, x): 
        batch_size = x.shape[0]
        x = x.view(batch_size, -1)
        h_1 = F.relu(self.input_fc(x))
        h_2=F.relu(self.hidden_fc(h_1))
        y_pred = self.output_fc(h_2)
        return y_pred

class Q4():
    def __init__(self,epochs,batch_size):
        self.train_df=pd.read_pickle(r'/content/drive/MyDrive/ass3_data/train_CIFAR.pickle')
        self.test_df=pd.read_pickle(r"/content/drive/MyDrive/ass3_data/test_CIFAR.pickle")
        self.train_x,self.train_y,self.test_x,self.test_y=self.preprocessData(self.train_df,self.test_df)
        self.EDA(self.train_y)
        self.epochs=epochs
        self.input_dimensions = 1000
        self.output_dimensions = 2
        self.batch_size=batch_size

    def EDA(self,train_y):
        sns.countplot(train_y)
        hist_Y_train = pd.Series(train_y).groupby(train_y).count()
        print(hist_Y_train)

    def return_photo(self,batch_file):
        assert batch_file.shape[1] == 3072
        dim = np.sqrt(1024).astype(int)
        r = batch_file[:, 0:1024].reshape(batch_file.shape[0], dim, dim, 1)
        g = batch_file[:, 1024:2048].reshape(batch_file.shape[0], dim, dim, 1)
        b = batch_file[:, 2048:3072].reshape(batch_file.shape[0], dim, dim, 1)
        photo = np.concatenate([r,g,b], -1)
        return photo

    def normalize(self,data):
        mean = data.mean(axis=(0,1,2)) / 255.0
        std = data.std(axis=(0,1,2)) / 255.0
        normalize = transforms.Normalize(mean=mean, std=std)
        return normalize

    def transform(self,train_x,test_x):
        train_transform = transforms.Compose([transforms.Resize(224),transforms.RandomHorizontalFlip(),transforms.ToTensor(),self.normalize(train_x)])
        test_transform = transforms.Compose([transforms.Resize(224),transforms.ToTensor(),self.normalize(test_x)])
        return train_transform,test_transform

    def preprocessData(self,train,test):
        train_x=train["X"]
        train_y=train["Y"]
        test_x=test["X"]
        test_y=test["Y"]
        return train_x,train_y,test_x,test_y

    def initialize(self):
        self.train_x = self.return_photo(self.train_x)
        self.test_x = self.return_photo(self.test_x)
        self.test_y = np.array(self.test_y)
        train_transform,test_transform=self.transform(self.train_x,self.test_x)
        trainset = CustomData(data=self.train_x, label=self.train_y, transform=train_transform)
        testset = CustomData(data=self.test_x, label=self.test_y, transform=test_transform)
        self.train_iterator = DataLoader(dataset=trainset,
                                batch_size=self.batch_size, 
                                shuffle=True,
                                num_workers=1)
        self.test_iterator = DataLoader(dataset=testset,
                                batch_size=self.batch_size, 
                                shuffle=False,
                                num_workers=1)
        self.model = NeuralNet(input_dim=self.input_dimensions,output_dim=self.output_dimensions)
        self.optimizer = optim.Adam(params=self.model.parameters())
        self.criterion = nn.CrossEntropyLoss()
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = self.model.to(self.device)
        self.criterion = self.criterion.to(self.device)

    def train(self,model, iterator, optimizer, criterion, device):
        epoch_acc = 0  
        model.train()
        for (x, y) in iterator:  
            x = x.to(device)
            y = y.to(device) 
            optimizer.zero_grad()
            alexnet.to(self.device)
            x=alexnet(x)
            x = x.to(device)
            y_pred = model(x)
            loss = criterion(y_pred, y)
            acc = self.calculate_accuracy(y_pred, y)
            loss.backward()
            optimizer.step()
            epoch_acc += acc.item()
        return  epoch_acc / len(iterator)

    def calculate_accuracy(self,y_pred, y):
        top_pred = y_pred.argmax(1, keepdim = True)
        correct = top_pred.eq(y.view_as(top_pred)).sum()
        acc = correct.float() / y.shape[0]
        return acc

    def evaluate(self,model, iterator, criterion, device):
        epoch_acc = 0
        model.eval()
        with torch.no_grad():
            for (x, y) in iterator:
                x = x.to(device)
                y = y.to(device)
                alexnet.to(self.device)
                x=alexnet(x)
                x = x.to(device)
                y_pred = model(x)
                loss = criterion(y_pred, y)
                acc = self.calculate_accuracy(y_pred, y)
                epoch_acc += acc.item()
        return epoch_acc / len(iterator)

    def get_predictions(self,model, iterator, device):
        model.eval()
        xx = []
        labels = []
        probs = []
        with torch.no_grad():
            for (x, y) in iterator:
                x = x.to(device)
                alexnet.to(self.device)
                x=alexnet(x)
                y_pred = model(x)
                y_prob = F.softmax(y_pred, dim = -1)
                top_pred = y_prob.argmax(1, keepdim = True)
                xx.append(x.cpu())
                labels.append(y.cpu())
                probs.append(y_prob.cpu())
        xx = torch.cat(xx, dim = 0)
        labels = torch.cat(labels, dim = 0)
        probs = torch.cat(probs, dim = 0)
        return xx, labels, probs

    def plot_confusion_matrix(self,labels, pred_labels):
        fig = plt.figure(figsize = (10, 10));
        ax = fig.add_subplot(1, 1, 1);
        cm = metrics.confusion_matrix(labels, pred_labels);
        cm = metrics.ConfusionMatrixDisplay(cm,display_labels=range(2));
        cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)

    def plot_roc(self):
        metrics.plot_roc_curve(clf, X_test, y_test)

    def fit(self):
        self.initialize()
        EPOCHS = self.epochs
        best_test_acc = float('inf')
        best_y_pred=None
        y_true=None
        train_acc_l=[]
        test_acc_l=[]
        for epoch in range(EPOCHS):
            train_acc = self.train(self.model, self.train_iterator, self.optimizer, self.criterion, self.device)
            test_acc= self.evaluate(self.model, self.test_iterator, self.criterion, self.device)
            train_acc_l.append(train_acc)
            test_acc_l.append(train_acc)
            if test_acc < best_test_acc:
                best_test_acc = test_acc
            print("Epoch:",epoch,",","Train Accuracy:",train_acc,",","Test Accuracy:",test_acc)
        x, labels, probs = self.get_predictions(self.model, self.test_iterator, self.device)
        y_pred = torch.argmax(probs, 1)
        self.plot_confusion_matrix(labels,y_pred)

        del self.model

obj=Q4(epochs=10,batch_size=64)
obj.fit()