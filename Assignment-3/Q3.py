# -*- coding: utf-8 -*-
"""Q3_my.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A6fj9nbKpw8gs6GlkoXDi2pWPhM7yJ7D
"""

from google.colab import drive
drive.mount('/content/drive')

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torch.utils.data as data
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

class CustomData(Dataset):
    def __init__(self,items,labels=None):
        self.X=items
        self.Y=labels
    def __len__(self):
        return(len(self.X))
    def __getitem__(self,i):
        x = torch.tensor(self.X.iloc[i].values.astype(float))
        y = torch.tensor(int(self.Y.iloc[i]))
        return (x,y)

class NeuralNet(nn.Module):
    def __init__(self, input_dim, output_dim,hiddenLayer_size):
        super().__init__()   
        self.input_fc = nn.Linear(input_dim, hiddenLayer_size)
        self.output_fc = nn.Linear(hiddenLayer_size, output_dim)
        
    def forward(self, x): 
        # print(x.shape)
        batch_size = x.shape[0]
        x = x.view(batch_size, -1)
        # print(x.shape)
        h_1 = F.relu(self.input_fc(x))
        y_pred = self.output_fc(h_1)
        
        return y_pred

class Q3():
    def __init__(self,learning_rate,epochs,hidden_units,batch_size):
        self.train_df=pd.read_csv('/content/drive/MyDrive/ass3_data/largeTrain.csv',header=None)
        self.val_df=pd.read_csv('/content/drive/MyDrive/ass3_data/largeValidation.csv',header=None)
        self.train_x,self.train_y,self.valid_x,self.valid_y=self.preprocessData(self.train_df,self.val_df)
        self.learning_rate=learning_rate
        self.epochs=epochs
        self.hidden_units=hidden_units
        self.input_dimensions = len(self.train_x.columns)
        self.output_dimensions = len(np.unique(self.train_y))
        self.batch_size=batch_size

    def preprocessData(self,train,validation):
        train_x=train.iloc[:,1:]
        train_y=train.iloc[:,0]
        valid_x=validation.iloc[:,1:]
        valid_y=validation.iloc[:,0]
        # train_x = train_x.astype(np.float32)
        # valid_x = valid_x.astype(np.float32)
        return train_x,train_y,valid_x,valid_y

    def initialize(self):
        # print(self.train_x.shape)
        train_data=CustomData(self.train_x,self.train_y)
        # print(train_data.X.shape)
        # print("-----------------------")
        # print(train_data.__len__)
        valid_data=CustomData(self.valid_x,self.valid_y)
        self.train_iterator = data.DataLoader(dataset=train_data,shuffle = True,batch_size = self.batch_size)
        self.valid_iterator = data.DataLoader(dataset=valid_data,batch_size = self.batch_size)
        # print(train_iterator)
        self.model = NeuralNet(input_dim=self.input_dimensions,output_dim=self.output_dimensions,hiddenLayer_size=self.hidden_units)
        self.optimizer = optim.Adam(params=self.model.parameters(), lr=self.learning_rate)
        self.criterion = nn.CrossEntropyLoss()
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = self.model.to(self.device)
        self.criterion = self.criterion.to(self.device)

    def train(self,model, iterator, optimizer, criterion, device):
        epoch_loss = 0
        model.train()
        for (x, y) in iterator:
            x = x.to(device)
            y = y.to(device)
            optimizer.zero_grad()  
            # print(x.shape)  
            # x=alexnet(x)  
            y_pred = model(x.float())
            loss = criterion(y_pred, y)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        return epoch_loss / len(iterator)

    def evaluate(self,model, iterator, criterion, device):
        epoch_loss = 0
        epoch_acc = 0
        model.eval()
        with torch.no_grad():  
            for (x, y) in iterator:
                x = x.to(device)
                y = y.to(device)
                y_pred= model(x.float())
                loss = criterion(y_pred, y)
                epoch_loss += loss.item()       
        return epoch_loss / len(iterator)

    def plot_data(self,train_losses, val_losses, learning_rate, hidden_units, epochs):
        print()
        title = "Training_vs_Validation_Loss_LearningRate("+str(learning_rate)+")_Hidden Units("+str(hidden_units)+")"
        epoch_range = [a for a in range(0,epochs)]
        plt.plot(epoch_range,train_losses,'r',label = 'Training Loss')
        plt.plot(epoch_range,val_losses,'b',label = 'Validation Loss')
        plt.xlabel("Epochs")
        plt.ylabel("Loss")
        plt.title(title)
        plt.legend()
        plt.savefig(title+'.png')
        plt.show()
        

    def fit(self,plotty):
        self.initialize()
        EPOCHS = self.epochs
        best_valid_loss = float('inf')
        train_losses=[]
        val_losses=[]
        for epoch in range(EPOCHS):
            train_loss=self.train(self.model, self.train_iterator, self.optimizer, self.criterion, self.device)
            val_loss=self.evaluate(self.model, self.valid_iterator, self.criterion, self.device)
            train_losses.append(train_loss)
            val_losses.append(val_loss)
        if plotty==True:
            self.plot_data(train_losses, val_losses, self.learning_rate, self.hidden_units, self.epochs)
        else:
            return train_losses[-1],val_losses[-1]
        del self.model

hidden_units=[5,20,50,100,200]
for i in range(len(hidden_units)):
    obj=Q3(learning_rate=0.01,epochs=100,hidden_units=hidden_units[i],batch_size=500)
    obj.fit(plotty=True)

""" PART 3i"""

hidden_units=[5,20,50,100,200]
train_losses=[]
val_losses=[]
for i in range(len(hidden_units)):
    obj=Q3(learning_rate=0.01,epochs=100,hidden_units=hidden_units[i],batch_size=500)
    train_loss,val_loss=obj.fit(plotty=False)
    train_losses.append(train_loss)
    val_losses.append(val_loss)
title="3i"
plt.plot(hidden_units,train_losses,'r',label = 'Training Loss')
plt.plot(hidden_units,val_losses,'b',label = 'Validation Loss')
plt.xlabel("Hidden Units")
plt.ylabel("Loss")
plt.title(title)
plt.legend()
plt.savefig(title+'.png')
plt.show()

"""For Learning Rate"""

obj=Q3(learning_rate=0.1,epochs=100,hidden_units=4,batch_size=500)
obj.fit()

obj=Q3(learning_rate=0.01,epochs=100,hidden_units=4,batch_size=500)
obj.fit()

obj=Q3(learning_rate=0.001,epochs=100,hidden_units=4,batch_size=500)
obj.fit()